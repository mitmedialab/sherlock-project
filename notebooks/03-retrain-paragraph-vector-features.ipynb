{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training set and train paragraph vectors\n",
    "Note: the paragraph vector model has been trained and is downloaded in the `prepare_feature_extraction()` function.\n",
    "\n",
    "Retraining is therefore not needed, but optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you need fully deterministic results between runs, set the following environment value prior to launching jupyter.\n",
    "# See comment in sherlock.features.paragraph_vectors.infer_paragraph_embeddings_features for more info.\n",
    "%env PYTHONHASHSEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import sys\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyarrow.parquet import ParquetFile\n",
    "\n",
    "from sherlock import helpers\n",
    "from sherlock.features.paragraph_vectors import (\n",
    "    initialise_nltk,\n",
    "    tagcol_paragraph_embeddings_features,\n",
    "    train_paragraph_embeddings_features\n",
    ")\n",
    "from sherlock.features.preprocessing import convert_string_lists_to_lists\n",
    "from sherlock.functional import extract_features_to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-02-10 19:51:19.513751\n"
     ]
    }
   ],
   "source": [
    "print(f'Started at {datetime.now()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and read in raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the raw and preprocessed data into ../data/data.zip.\n",
      "Data was downloaded.\n"
     ]
    }
   ],
   "source": [
    "helpers.download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = pd.read_parquet('../data/data/raw/train_values.parquet')\n",
    "train_labels = pd.read_parquet('../data/data/raw/train_labels.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 412059/412059 [01:47<00:00, 3841.46it/s] \n"
     ]
    }
   ],
   "source": [
    "train_samples_converted, y_train = convert_string_lists_to_lists(train_samples, train_labels, \"values\", \"type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised NLTK, process took 0:00:00.340159 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/madelon/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/madelon/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "initialise_nltk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: <class 'pandas.core.series.Series'>, length=412059\n",
      "Labels:  <class 'numpy.ndarray'>, length=412059\n"
     ]
    }
   ],
   "source": [
    "samples = train_samples_converted.dropna()\n",
    "print(f'Samples: {type(samples)}, length={len(samples)}')\n",
    "\n",
    "labels = train_labels.values.flatten()\n",
    "print(f'Labels:  {type(labels)}, length={len(labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging columns\n",
      "Tagged Columns Doc2Vec Model, process took 0:07:04.637667 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "print('Tagging columns')\n",
    "cols = tagcol_paragraph_embeddings_features(samples, labels)\n",
    "\n",
    "print(f'Tagged Columns Doc2Vec Model, process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Doc2Vec model in 400 dimensions\n",
      "Trained Doc2Vec Model, 400 dim, process took 0:22:22.303905 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "vec_dim = 400\n",
    "print(f'Training Doc2Vec model in {vec_dim} dimensions')\n",
    "\n",
    "train_paragraph_embeddings_features(cols, vec_dim)\n",
    "\n",
    "print(f'Trained Doc2Vec Model, {vec_dim} dim, process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished at 2022-02-09 19:38:41.865764\n"
     ]
    }
   ],
   "source": [
    "print(f'Finished at {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
