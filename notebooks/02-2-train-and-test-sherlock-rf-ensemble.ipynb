{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test Sherlock when ensembled with a RF classifier\n",
    "To boost the performance of Sherlock, it can be combined with a RF classifier.\n",
    "\n",
    "The scripts below show the procedure for doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'sherlock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you need fully deterministic results between runs, set the following environment value prior to launching jupyter.\n",
    "\n",
    "# See comment in sherlock.features.paragraph_vectors.infer_paragraph_embeddings_features for more info.\n",
    "%env PYTHONHASHSEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "from sherlock.deploy.model import SherlockModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-02-21 14:44:58.387328\n",
      "Load data (train) process took 0:00:07.072707 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_train = pd.read_parquet('../data/data/processed/train.parquet')\n",
    "y_train = pd.read_parquet('../data/data/raw/train_labels.parquet').values.flatten()\n",
    "\n",
    "y_train = np.array([x.lower() for x in y_train])\n",
    "\n",
    "print(f'Load data (train) process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct types for columns in the Dataframe (should be all float32):\n",
      "{dtype('float32')}\n"
     ]
    }
   ],
   "source": [
    "print('Distinct types for columns in the Dataframe (should be all float32):')\n",
    "print(set(X_train.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-02-21 14:16:45.455219\n",
      "Load data (validation) process took 0:00:02.024156 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_validation = pd.read_parquet('../data/data/processed/validation.parquet')\n",
    "y_validation = pd.read_parquet('../data/data/raw/val_labels.parquet').values.flatten()\n",
    "\n",
    "y_validation = np.array([x.lower() for x in y_validation])\n",
    "\n",
    "print(f'Load data (validation) process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, X_validation], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([x.lower() for x in itertools.chain(y_train, y_validation)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Voting Classifier using RFC and ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-02-21 14:17:08.147857\n",
      "Finished at 2022-02-21 14:38:09.947917, took 0:21:01.802720 seconds\n"
     ]
    }
   ],
   "source": [
    "# n_estimators=300 gives a slightly better result (0.1%), but triples the fit time\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=13, n_jobs=-1)),\n",
    "        ('et', ExtraTreesClassifier(n_estimators=100, random_state=13, n_jobs=-1))\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make individual (trained) estimators available\n",
    "rf_clf = voting_clf.estimators_[0]\n",
    "et_clf = voting_clf.estimators_[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-02-21 14:38:10.601540\n",
      "Trained and saved new model.\n",
      "Finished at 2022-02-21 14:38:12.493349, took 0:00:01.891821 seconds\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_test = pd.read_parquet('../data/data/processed/test.parquet')\n",
    "y_test = pd.read_parquet('../data/data/raw/test_labels.parquet').values.flatten()\n",
    "\n",
    "y_test = np.array([x.lower() for x in y_test])\n",
    "\n",
    "print('Trained and saved new model.')\n",
    "print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['address', 'affiliate', 'affiliation', 'age', 'album', 'area',\n",
       "       'artist', 'birth date', 'birth place', 'brand', 'capacity',\n",
       "       'category', 'city', 'class', 'classification', 'club', 'code',\n",
       "       'collection', 'command', 'company', 'component', 'continent',\n",
       "       'country', 'county', 'creator', 'credit', 'currency', 'day',\n",
       "       'depth', 'description', 'director', 'duration', 'education',\n",
       "       'elevation', 'family', 'file size', 'format', 'gender', 'genre',\n",
       "       'grades', 'industry', 'isbn', 'jockey', 'language', 'location',\n",
       "       'manufacturer', 'name', 'nationality', 'notes', 'operator',\n",
       "       'order', 'organisation', 'origin', 'owner', 'person', 'plays',\n",
       "       'position', 'product', 'publisher', 'range', 'rank', 'ranking',\n",
       "       'region', 'religion', 'requirement', 'result', 'sales', 'service',\n",
       "       'sex', 'species', 'state', 'status', 'symbol', 'team', 'team name',\n",
       "       'type', 'weight', 'year'], dtype='<U14')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.load(\n",
    "    f\"../model_files/classes_{model_id}.npy\",\n",
    "    allow_pickle=True\n",
    ")\n",
    "classes = np.array([cls.lower() for cls in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (classes == sorted(classes)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_labels(y_pred_proba, classes):\n",
    "    y_pred_int = np.argmax(y_pred_proba, axis=1)\n",
    "    \n",
    "    encoder = LabelEncoder()\n",
    "    encoder.classes_ = classes\n",
    "\n",
    "    return encoder.inverse_transform(y_pred_int)\n",
    "\n",
    "\n",
    "def prediction_summary(y_test, predicted_labels):\n",
    "    print(f'prediction count {len(predicted_labels)}, type = {type(predicted_labels)}')\n",
    "\n",
    "    size=len(y_test)\n",
    "\n",
    "    print(f'f1 score {f1_score(y_test[:size], predicted_labels[:size], average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict: RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_rfc_proba = rf_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 137353, type = <class 'numpy.ndarray'>\n",
      "f1 score 0.8912755744265719\n"
     ]
    }
   ],
   "source": [
    "prediction_summary(y_test, predicted_labels(predicted_rfc_proba, classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict: ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_etc_proba = et_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 137353, type = <class 'numpy.ndarray'>\n",
      "f1 score 0.8883526561931331\n"
     ]
    }
   ],
   "source": [
    "prediction_summary(y_test, predicted_labels(predicted_etc_proba, classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict: Voting Classifier (RFC + ETC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_voting_proba = voting_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 137353, type = <class 'numpy.ndarray'>\n",
      "f1 score 0.8940645473980389\n"
     ]
    }
   ],
   "source": [
    "prediction_summary(y_test, predicted_labels(predicted_voting_proba, classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict: Sherlock NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SherlockModel()\n",
    "model.initialize_model_from_json(with_weights=True, model_id=\"sherlock\")\n",
    "predicted_sherlock_proba = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 137353, type = <class 'numpy.ndarray'>\n",
      "f1 score 0.8951410029373902\n"
     ]
    }
   ],
   "source": [
    "prediction_summary(y_test, predicted_labels(predicted_sherlock_proba, classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict: Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = []\n",
    "    \n",
    "for i in range(len(y_test)):\n",
    "    nn_probs = predicted_sherlock_proba[i]\n",
    "    voting_probs = predicted_voting_proba[i]\n",
    "    \n",
    "    x = nn_probs + voting_probs\n",
    "    x = x / 2\n",
    "\n",
    "    combined.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 137353, type = <class 'numpy.ndarray'>\n",
      "f1 score 0.905491661885665\n"
     ]
    }
   ],
   "source": [
    "labels = predicted_labels(combined, classes)\n",
    "\n",
    "prediction_summary(y_test, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, labels, output_dict=True)\n",
    "\n",
    "class_scores = list(filter(lambda x: isinstance(x, tuple) and isinstance(x[1], dict) and 'f1-score' in x[1] and x[0] in classes, list(report.items())))\n",
    "\n",
    "class_scores = sorted(class_scores, key=lambda item: item[1]['f1-score'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_table(class_scores):\n",
    "    print(f\"\\t\\tf1-score\\tprecision\\trecall\\t\\tsupport\")\n",
    "\n",
    "    for key, value in class_scores:\n",
    "        if len(key) >= 8:\n",
    "            tabs = '\\t' * 1\n",
    "        else:\n",
    "            tabs = '\\t' * 2\n",
    "\n",
    "        print(f\"{key}{tabs}{value['f1-score']:.3f}\\t\\t{value['precision']:.3f}\\t\\t{value['recall']:.3f}\\t\\t{value['support']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tf1-score\tprecision\trecall\t\tsupport\n",
      "grades\t\t0.995\t\t0.994\t\t0.995\t\t1765\n",
      "isbn\t\t0.990\t\t0.992\t\t0.989\t\t1430\n",
      "industry\t0.986\t\t0.985\t\t0.988\t\t2958\n",
      "jockey\t\t0.985\t\t0.984\t\t0.987\t\t2819\n",
      "currency\t0.979\t\t0.985\t\t0.973\t\t405\n"
     ]
    }
   ],
   "source": [
    "score_table(class_scores[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom 5 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tf1-score\tprecision\trecall\t\tsupport\n",
      "rank\t\t0.738\t\t0.678\t\t0.810\t\t2983\n",
      "person\t\t0.695\t\t0.767\t\t0.636\t\t579\n",
      "sales\t\t0.615\t\t0.667\t\t0.571\t\t322\n",
      "director\t0.604\t\t0.661\t\t0.556\t\t225\n",
      "ranking\t\t0.569\t\t0.823\t\t0.435\t\t439\n"
     ]
    }
   ],
   "source": [
    "score_table(class_scores[len(class_scores)-5:len(class_scores)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Scores (by class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "       address      0.929     0.951     0.940      3003\n",
      "     affiliate      0.949     0.819     0.879       204\n",
      "   affiliation      0.975     0.958     0.966      1768\n",
      "           age      0.891     0.955     0.922      3033\n",
      "         album      0.894     0.895     0.894      3035\n",
      "          area      0.892     0.836     0.863      1987\n",
      "        artist      0.810     0.884     0.846      3043\n",
      "    birth date      0.983     0.969     0.976       479\n",
      "   birth place      0.939     0.919     0.929       418\n",
      "         brand      0.849     0.695     0.764       574\n",
      "      capacity      0.851     0.771     0.809       362\n",
      "      category      0.927     0.898     0.912      3087\n",
      "          city      0.870     0.910     0.890      2966\n",
      "         class      0.921     0.923     0.922      2971\n",
      "classification      0.946     0.874     0.909       587\n",
      "          club      0.975     0.957     0.966      2977\n",
      "          code      0.921     0.925     0.923      2956\n",
      "    collection      0.987     0.935     0.960       476\n",
      "       command      0.941     0.918     0.929      1045\n",
      "       company      0.913     0.898     0.905      3041\n",
      "     component      0.904     0.892     0.898      1226\n",
      "     continent      0.887     0.930     0.908       227\n",
      "       country      0.897     0.957     0.926      3038\n",
      "        county      0.944     0.964     0.954      2959\n",
      "       creator      0.807     0.841     0.824       347\n",
      "        credit      0.890     0.832     0.860       941\n",
      "      currency      0.985     0.973     0.979       405\n",
      "           day      0.948     0.914     0.931      3038\n",
      "         depth      0.945     0.945     0.945       947\n",
      "   description      0.809     0.884     0.845      3042\n",
      "      director      0.661     0.556     0.604       225\n",
      "      duration      0.935     0.955     0.945      3000\n",
      "     education      0.887     0.856     0.872       313\n",
      "     elevation      0.961     0.955     0.958      1299\n",
      "        family      0.967     0.905     0.935       746\n",
      "     file size      0.946     0.867     0.905       361\n",
      "        format      0.969     0.960     0.964      2956\n",
      "        gender      0.860     0.836     0.848      1030\n",
      "         genre      0.969     0.953     0.961      1163\n",
      "        grades      0.994     0.995     0.995      1765\n",
      "      industry      0.985     0.988     0.986      2958\n",
      "          isbn      0.992     0.989     0.990      1430\n",
      "        jockey      0.984     0.987     0.985      2819\n",
      "      language      0.923     0.947     0.935      1474\n",
      "      location      0.901     0.838     0.868      2949\n",
      "  manufacturer      0.876     0.828     0.851       945\n",
      "          name      0.733     0.769     0.751      3017\n",
      "   nationality      0.906     0.708     0.795       424\n",
      "         notes      0.750     0.847     0.796      2303\n",
      "      operator      0.819     0.854     0.836       404\n",
      "         order      0.860     0.877     0.869      1462\n",
      "  organisation      0.852     0.855     0.853       262\n",
      "        origin      0.955     0.905     0.930      1439\n",
      "         owner      0.941     0.874     0.906      1673\n",
      "        person      0.767     0.636     0.695       579\n",
      "         plays      0.856     0.915     0.885      1513\n",
      "      position      0.848     0.850     0.849      3057\n",
      "       product      0.878     0.886     0.882      2647\n",
      "     publisher      0.904     0.903     0.904       880\n",
      "         range      0.885     0.797     0.839       577\n",
      "          rank      0.678     0.810     0.738      2983\n",
      "       ranking      0.823     0.435     0.569       439\n",
      "        region      0.905     0.844     0.873      2740\n",
      "      religion      0.975     0.926     0.950       340\n",
      "   requirement      0.942     0.817     0.875       300\n",
      "        result      0.968     0.947     0.958      2920\n",
      "         sales      0.667     0.571     0.615       322\n",
      "       service      0.970     0.929     0.949      2222\n",
      "           sex      0.940     0.938     0.939      2997\n",
      "       species      0.930     0.952     0.941       819\n",
      "         state      0.940     0.962     0.951      3030\n",
      "        status      0.949     0.943     0.946      3100\n",
      "        symbol      0.963     0.971     0.967      1752\n",
      "          team      0.867     0.871     0.869      3011\n",
      "     team name      0.898     0.842     0.869      1639\n",
      "          type      0.923     0.882     0.902      2909\n",
      "        weight      0.963     0.950     0.956      2963\n",
      "          year      0.966     0.946     0.956      3015\n",
      "\n",
      "      accuracy                          0.905    137353\n",
      "     macro avg      0.903     0.880     0.890    137353\n",
      "  weighted avg      0.907     0.905     0.905    137353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mismatches: 12994 (F1 score: 0.905491661885665)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('name', 697),\n",
       " ('rank', 566),\n",
       " ('location', 479),\n",
       " ('position', 460),\n",
       " ('region', 427),\n",
       " ('team', 388),\n",
       " ('artist', 353),\n",
       " ('notes', 352),\n",
       " ('description', 352),\n",
       " ('type', 342),\n",
       " ('area', 326),\n",
       " ('album', 320),\n",
       " ('category', 316),\n",
       " ('company', 310),\n",
       " ('product', 301),\n",
       " ('city', 266),\n",
       " ('day', 261),\n",
       " ('team name', 259),\n",
       " ('ranking', 248),\n",
       " ('class', 229),\n",
       " ('code', 222),\n",
       " ('person', 211),\n",
       " ('owner', 210),\n",
       " ('sex', 185),\n",
       " ('order', 180),\n",
       " ('status', 178),\n",
       " ('brand', 175),\n",
       " ('gender', 169),\n",
       " ('manufacturer', 163),\n",
       " ('year', 163),\n",
       " ('credit', 158),\n",
       " ('service', 158),\n",
       " ('result', 154),\n",
       " ('weight', 149),\n",
       " ('address', 146),\n",
       " ('sales', 138),\n",
       " ('duration', 136),\n",
       " ('age', 136),\n",
       " ('origin', 136),\n",
       " ('component', 133),\n",
       " ('country', 130),\n",
       " ('club', 129),\n",
       " ('plays', 128),\n",
       " ('nationality', 124),\n",
       " ('format', 119),\n",
       " ('range', 117),\n",
       " ('state', 115),\n",
       " ('county', 108),\n",
       " ('director', 100),\n",
       " ('command', 86),\n",
       " ('publisher', 85),\n",
       " ('capacity', 83),\n",
       " ('language', 78),\n",
       " ('affiliation', 75),\n",
       " ('classification', 74),\n",
       " ('family', 71),\n",
       " ('operator', 59),\n",
       " ('elevation', 58),\n",
       " ('creator', 55),\n",
       " ('requirement', 55),\n",
       " ('genre', 55),\n",
       " ('depth', 52),\n",
       " ('symbol', 51),\n",
       " ('file size', 48),\n",
       " ('education', 45),\n",
       " ('species', 39),\n",
       " ('organisation', 38),\n",
       " ('affiliate', 37),\n",
       " ('jockey', 36),\n",
       " ('industry', 36),\n",
       " ('birth place', 34),\n",
       " ('collection', 31),\n",
       " ('religion', 25),\n",
       " ('continent', 16),\n",
       " ('isbn', 16),\n",
       " ('birth date', 15),\n",
       " ('currency', 11),\n",
       " ('grades', 8)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = len(y_test)\n",
    "mismatches = list()\n",
    "\n",
    "for idx, k1 in enumerate(y_test[:size]):\n",
    "    k2 = labels[idx]\n",
    "\n",
    "    if k1 != k2:\n",
    "        mismatches.append(k1)\n",
    "#        if k1 in ('brand'):\n",
    "#        print(f'[{idx}] expected \"{k1}\" but predicted \"{k2}\"')\n",
    "        \n",
    "f1 = f1_score(y_test[:size], labels[:size], average=\"weighted\")\n",
    "print(f'Total mismatches: {len(mismatches)} (F1 score: {f1})')\n",
    "\n",
    "data = Counter(mismatches)\n",
    "data.most_common()   # Returns all unique items and their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = pd.read_parquet('../data/data/raw/test_values.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted \"age\", actual label \"position\". Actual values:\n",
      "[[2, 4]]\n"
     ]
    }
   ],
   "source": [
    "idx = 541\n",
    "original = test_samples.iloc[idx]\n",
    "converted = original.apply(literal_eval).to_list()\n",
    "\n",
    "print(f'Predicted \"{labels[idx]}\", actual label \"{y_test[idx]}\". Actual values:\\n{converted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed at 2022-02-21 14:53:39.160195\n"
     ]
    }
   ],
   "source": [
    "print(f'Completed at {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
